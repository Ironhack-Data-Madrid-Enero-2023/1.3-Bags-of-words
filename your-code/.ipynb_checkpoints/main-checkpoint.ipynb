{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `docs` array that contains the paths of `doc1.txt`, `doc2.txt`, and `doc3.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs = ['/home/hefesto/Desktop/1.3-Bags-of-words/your-code/doc1.txt','/home/hefesto/Desktop/1.3-Bags-of-words/your-code/doc2.txt', '/home/hefesto/Desktop/1.3-Bags-of-words/your-code/doc3.txt']\n",
    "docs = ['doc1.txt','doc2.txt','doc3.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an empty array `corpus` that will contain the content strings of the docs. Loop `docs` and read the content of each doc into the `corpus` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ironhack is cool', 'i love ironhack', 'i am a student at ironhack']\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"for doc in docs: \\n    with open(doc) as lectura:\\n        corpus.append(lectura.read().lower().translate(str.maketrans('', '', string.punctuation)))\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "corpus = [open(doc).read().lower().translate(str.maketrans('', '', string.punctuation)) for doc in docs]\n",
    "\n",
    "print(corpus)\n",
    "print(type(corpus))\n",
    "\n",
    "\n",
    "#corpus.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "'''for doc in docs: \n",
    "    with open(doc) as lectura:\n",
    "        corpus.append(lectura.read().lower().translate(str.maketrans('', '', string.punctuation)))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `corpus`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen:\n",
    "\n",
    "```['ironhack is cool', 'i love ironhack', 'i am a student at ironhack']```\n",
    "\n",
    "However, if your output is:\n",
    "\n",
    "```['Ironhack is cool.', 'I love Ironhack.', 'I am a student at Ironhack.']```\n",
    "\n",
    "This means you didn't:\n",
    "\n",
    "1. Remove punctuation from the strings;\n",
    "\n",
    "1. Convert strings to lowercase.\n",
    "\n",
    "Revise your code above until you receive the correct output for `corpus`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define `bag_of_words` as an empty array. It will contain the unique terms in `corpus`.\n",
    "\n",
    "Loop through `corpus`. In each loop, do the following:\n",
    "\n",
    "1. Break the string into an array of terms. \n",
    "1. Create a sub-loop to iterate the terms array. \n",
    "  * In each sub-loop, you'll check if the current term is already contained in `bag_of_words`. If not in `bag_of_words`, append it to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ironhack', 'is', 'cool', 'i', 'love', 'am', 'a', 'student', 'at']\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = []\n",
    "\n",
    "for i in corpus:\n",
    "    for word in i.split():\n",
    "        if word not in bag_of_words:\n",
    "            bag_of_words.append(word)\n",
    "            \n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `bag_of_words`. You should see: \n",
    "\n",
    "```['ironhack', 'is', 'cool', 'i', 'love', 'am', 'a', 'student', 'at']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define an empty array called `term_freq`. Loop `corpus` for a second time. In each loop, create a sub-loop to iterate the terms in `bag_of_words`. Count how many times each term appears in each doc of `corpus`. Append the term-frequency array to `term_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "term_freq = []\n",
    "\n",
    "for doc in corpus:\n",
    "    x = []\n",
    "    for wurd in bag_of_words:\n",
    "            if wurd in doc.split():\n",
    "                x.append(1)\n",
    "            else:\n",
    "                x.append(0)\n",
    "    term_freq.append(x)\n",
    "            \n",
    "print(term_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print `term_freq`. You should see:\n",
    "\n",
    "```[[1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 1, 1, 1, 1]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your answer is correct, congratulations! You've solved the challenge!**\n",
    "\n",
    "If not, go back and check for errors in your code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
